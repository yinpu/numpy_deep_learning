{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实现神经网络的前向传播"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入MNIST数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "from datasets.mnist import load_mnist\n",
    "import numpy as np\n",
    "# 第一次调用会花费几分钟 ……\n",
    "(x_train, y_train), (x_test, y_test) = load_mnist(flatten=True, normalize=True)\n",
    "# 输出各个数据的形状\n",
    "print(x_train.shape) # (60000, 784)\n",
    "print(y_train.shape) # (60000,)\n",
    "print(x_test.shape) # (10000, 784)\n",
    "print(y_test.shape) # (10000,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现神经网络的前向传播\n",
    "\n",
    "1. 实现激活函数（relu、sigmoid、softmax）\n",
    "2. 实现三层全连接神经网络\n",
    "3. 使用神经网络进行前向传播\n",
    "4. 加载已训练好的神经网络进行推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 激活函数\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def softmax(x):\n",
    "    x_max = np.max(x, axis=-1, keepdims=True)\n",
    "    x = x-x_max  #防止溢出\n",
    "    exp_x = np.exp(x)\n",
    "    return exp_x/np.sum(exp_x, axis=-1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三层全连接网络\n",
    "\n",
    "这里实现的三层全连接网络模型细节如下\n",
    "- 神经网络的输入层有784个神经元，输出层有10个神经元。\n",
    "- 输入层的784这个数字来源于图像大小的28 × 28 = 784。\n",
    "- 输出层的10这个数字来源于10类别分类（数字0到9，共10类别）。-\n",
    "- 神经网络有2个隐藏层，第1个隐藏层有50个神经元，第2个隐藏层有100个神经元。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化神经网络参数\n",
    "def init_network():\n",
    "    network = {}\n",
    "    network['W1'] = np.random.normal(size=(784, 50))\n",
    "    network['b1'] = np.random.normal(size=(50,))\n",
    "    network['W2'] = np.random.normal(size=(50, 100))\n",
    "    network['b2'] = np.random.normal(size=(100,))\n",
    "    network['W3'] = np.random.normal(size=(100, 10))\n",
    "    network['b3'] = np.random.normal(size=(10,))\n",
    "    return network\n",
    "\n",
    "# 前向传播\n",
    "def forward(netwok, x):\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "    a1 = np.dot(x, W1)+b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2)+b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = np.dot(z2, W3)+b3\n",
    "    y = softmax(a3)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n",
      "accuracy:0.1137\n"
     ]
    }
   ],
   "source": [
    "# 使用神经网络进行前向传播\n",
    "network = init_network()\n",
    "y = forward(network, x_test)\n",
    "print(y.shape)\n",
    "# 计算准确性\n",
    "accuracy_cnt = (np.argmax(y, axis=1)==y_test).sum()\n",
    "print(f\"accuracy:{accuracy_cnt/len(y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载已训练好的模型进行推断\n",
    "\n",
    "从上面可以看到随机初始化的神经网络（尚未训练）准确率约为10%（随机猜测的结果）\n",
    "\n",
    "由于这一节尚未涉及训练过程，这里将使用一个已训练好的权重，看一下效果\n",
    "\n",
    "已训练好的权重位于\"weights/sample_weight.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.9352\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"weights/sample_weight.pkl\", 'rb') as f:\n",
    "    network = pickle.load(f)\n",
    "y = forward(network, x_test)\n",
    "# 计算准确性\n",
    "accuracy_cnt = (np.argmax(y, axis=1)==y_test).sum()\n",
    "print(f\"accuracy:{accuracy_cnt/len(y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实现批处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9352\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "accuracy_cnt = 0\n",
    "for i in range(0, len(x_test), batch_size):\n",
    "    x_batch = x_test[i:i+batch_size]\n",
    "    y_batch = y_test[i:i+batch_size]\n",
    "    y = forward(network, x_batch)\n",
    "    accuracy_cnt += (np.argmax(y, axis=1)==y_batch).sum()\n",
    "print(accuracy_cnt/len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9458315d5836b2bfd4e1bebc345bce04a12d69e51166d3a8e658c592918a5802"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
